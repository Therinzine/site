<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.104.3"><link rel=canonical type=text/html href=https://purduearc.com/wiki/active-projects/drone-delivery/><link rel=alternate type=application/rss+xml href=https://purduearc.com/wiki/active-projects/drone-delivery/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Drone Delivery | Purdue ARC</title><meta name=description content="Building and programming a drone that can deliver packages
"><meta property="og:title" content="Drone Delivery"><meta property="og:description" content="Building and programming a drone that can deliver packages
"><meta property="og:type" content="website"><meta property="og:url" content="https://purduearc.com/wiki/active-projects/drone-delivery/"><meta property="og:site_name" content="Purdue ARC"><meta itemprop=name content="Drone Delivery"><meta itemprop=description content="Building and programming a drone that can deliver packages
"><meta name=twitter:card content="summary"><meta name=twitter:title content="Drone Delivery"><meta name=twitter:description content="Building and programming a drone that can deliver packages
"><link rel=preload href=/scss/main.min.467da06906b803b76be4b3f8baac843ce24f17fb1278285ec45e30026bec4e0b.css as=style><link href=/scss/main.min.467da06906b803b76be4b3f8baac843ce24f17fb1278285ec45e30026bec4e0b.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-00000000-0","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class=navbar-logo></span><span class=font-weight-bold>Purdue ARC</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/about/><span>About</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/wiki/><span class=active>Wiki</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/blog/><span>Blog</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/join/><span>Join</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/wiki/active-projects/drone-delivery/>Return to the regular view of this page</a>.</p></div><h1 class=title>Drone Delivery</h1><div class=lead>Building and programming a drone that can deliver packages</div><ul><li>1: <a href=#pg-81f9cbdbe61c3f4f5fcc1f73b61ccff9>Pre-flight path planning</a></li></ul><div class=content><h2 id=goal>Goal</h2><p>Given a destination, autonomously deliver a package and return with no human intervention.</p><h2 id=subteams>Subteams</h2><ul><li>Hardware: Designs and builds the drone, its sensors, and package container.</li><li>Flight controls: Programs the drone using Robot Operating System (ROS) to ingest data and fly a given path. Tests flight in the simulation software Gazebo before real-world testing.</li><li>Obstacle avoidance: Programs the drone to avoid obstacles in its planned flight path encountered while its flying. Uses Intel Realsense camera and its depth sensor to recognize near and far objects using computer vision and generate a 3D data structure of its surroundings.</li></ul><h2 id=technology>Technology</h2><h3 id=drone-hardware>Drone hardware</h3><ul><li>Motors: T-Motor U7 V2.0<ul><li>6 total</li><li>4.55kg Lift / Motor</li><li>Over 27kg of Thrust!</li><li>47.5A Draw at 100% Throttle</li></ul></li><li>Props: Tarot 1855<ul><li>18&rsquo;&rsquo; Diameter</li><li>5.5&rsquo;&rsquo; Pitch</li><li>Carbon fiber</li></ul></li><li>Frame: Tarot T960<ul><li>Hexacopter Configuration</li><li>960mm Diameter</li></ul></li><li>Battery: Tattu Plus LiPo Battery Pack<ul><li>22000mAh</li><li>25C Discharge Rate</li><li>6S</li><li>22.2V</li></ul></li><li>Power Delivery (ESC): xRotor 40A<ul><li>60A Max Current</li><li>Rated for 6S LiPo (22.2V)</li></ul></li><li>Flight Controller: Pixhawk 6c<ul><li>H7 Processor @ 480MHZ<ul><li>PX4 Firmware</li></ul></li><li>Redundant IMU</li><li>M8N GPS</li></ul></li><li>Camera: Intel RealSense D453<ul><li>Stereoscopic Depth Sensing</li><li>&lt; 2% Error Within 2m</li></ul></li><li>Companion Computer: Jetson Nano<ul><li>Quad-core AMD Cortex</li><li>4GB Onboard Memory</li><li>128 Cuda Cores</li></ul></li><li>Infrared sensor: TBD<ul><li>Used to find precise distance from ground to see if landing area is safe.</li></ul></li><li>Camera rotator/gimbal<ul><li>Will rotate camera from forward-facing to downwards to ensure safe landing area.</li><li>Stabilization of camera during flight to minimize noise in optical data</li></ul></li><li>Parcel container<ul><li>Structure<ul><li>Minimize impact on aerodynamic performance</li><li>Safe to access for users</li></ul></li><li>Food Preservation<ul><li>Keep food hot, or cold, to ensure minimal loss in quality during delivery</li></ul></li></ul></li></ul><h3 id=drone-software>Drone software</h3><ul><li><a href=https://px4.io/software/software-overview/>PX4</a>: PX4 is the firmware that runs on the Pixhawk 6c. It controls and recieves data all of the motors and sensors attached.</li><li><a href=http://qgroundcontrol.com/>QGroundControl</a>: QGroundControl is the application used to connect to, configure, and program the drone to fly autonomously.</li><li>Robot Operating System (ROS):</li><li>MAVSDK:</li><li>MAVLink:</li></ul><h3 id=flight-simulator>Flight simulator</h3><p>The flight simulator will run the same software we are programming the drone with on a drone in a simulator. This will allow us to test and quickly improve our sofware without risking breaking the actual drone and taking the time to fly it.</p><ul><li>Initial testing: Gazebo</li><li>Complete solution: <a href=https://cesium.com/platform/cesiumjs/>CesiumJS</a></li></ul><h3 id=obstacle-avoidance>Obstacle avoidance</h3><ul><li>OpenCV</li></ul><p>TODO</p><h3 id=pre-flight-path-planning>Pre-flight path planning</h3><ul><li>OpenStreetMap</li><li>Photogrammetry</li><li>Open3D</li><li>Rasterio</li></ul><h3 id=pathfinding-algorithm>Pathfinding algorithm</h3><p>D* will be the chosen pathfinding algorithm and will aim to be used by both the obstacle avoidance and pre-flight planning software.</p><h3 id=flight-control-command-pipeline>Flight control command pipeline</h3><p>Generate a pipeline between the software that is written by various teams and the hardware that must run the code.</p><ul><li>Interface the pixhawk with external computers.</li><li>Work with ROS in order to create sub-systems that interact neatly.</li></ul></div></div><div class=td-content style=page-break-before:always><h1 id=pg-81f9cbdbe61c3f4f5fcc1f73b61ccff9>1 - Pre-flight path planning</h1><div class=lead>How we plan the path the drone will take before it takes flight</div><h2 id=why>Why</h2><p>The drone should fly a path known not to have obstacles so that we can minimize the amount of time avoiding obstacles during its flight.</p><h2 id=getting-the-obstacle-data>Getting the obstacle data</h2><p>We can get data of obstacles we want to avoid like buildings, trees, and lightposts from a geospatial data source.</p><p>The geospatial data source we decided to use for our initial implementation was <a href=https://www.openstreetmap.org>OpenStreetMap</a>. OpenStreetMap is a free-to-use map of the world that can be contributed to by anyone. A large variety of features can be mapped in OpenStreetMap including all of the obstacles we need to avoid: buildings, trees, and lightposts. Because OpenStreetMap data is free, can be updated by ourselves if data is missing, and has all the obstacles we need to avoid, it is a clear choice over Google Maps which is costly, cannot be updated, and does not have data on eveything we need to avoid.</p><p>OpenStreetMap data is is made up of features. There are 3 types of features: points, lines, and areas. Lines and areas are ordered lists of points. Each point has a laditude and longitude and thus determines the position of a feature or the shape of a line or area in the world. To describe the type of feature such as &ldquo;building&rdquo; and attributes that feature has such as &ldquo;levels&rdquo; or &ldquo;color&rdquo;, every feature has a list of key-value pairs (a map/dictionary).</p><p>We only want to get all of the buildings, trees, and streetlight features and not any of the other features in an area in OpenStreetMap, so we need to filter the features in a selected area by their tags.</p><p>We can use the Overpass API querying service to get only these features. The Overpass API can be easily interfaced through by using <a href=https://overpass-turbo.eu/>Overpass Turbo</a>. We can easily create a query clicking the <code>Wizard</code> button at the top and inputting the tags we want.</p><p>Every building in OSM has a tag with the key <code>building</code>. The value of the <code>building</code> tag determines the type of the building. For example, <code>building=school</code>. We don&rsquo;t care about the type of the building so we can just add <code>building=*</code> to get all of the buildings that have a tag with the key <code>buildling</code> regardless of its value.</p><p>OSM allows users to document map individual parts of buildings to distinguish which parts have different attributes. For example, one part of a building might have more levels than another. The key for getting these &ldquo;building part&rdquo; features is <code>building:part</code>. So, we can add <code>or building:part=*</code> to also select all of these building parts.</p><p>Finally, we want to get all of the trees. The tag for a tree is <code>natural=tree</code> so we can add <code>or natural=tree</code> to also select all of the trees.</p><p>So, our final input inside of the query wizard should be <code>building=* or building:part=* or natural=tree</code>. You can then click <code>Build query</code> and the actual Overpass Query Language query text will appear on the left.</p><p>To select the area of data you want to get, click the picture icon in the upper left of the map and click adjust the box on the map to &ldquo;manually select the bbox&rdquo;.</p><p>Now, we click <code>Run</code> in the upper right to run the query and return the data we need.</p><blockquote><p>Note, you might have selected a large area and it will give you a warning you are returning a lot of data. Click <code>continue anyway</code>. You can minimize the impact this will have on your computer by disabling the results from showing on the map. This is done by removing the <code>>; out skel qt;</code> at the end of the query and re-running it.</p></blockquote><p>You can browse the data returned visually on the map or by clicking the <code>Data</code> button in the upper right.</p><p>The next step is to export the data. This can be done by clicking the <code>Export</code> button at the top and selecting which file format to export to. What file format should be exported is dependent on the type of occupancy matrix needed. Read the following section to understand what an occupancy matrix is and how it will help us find a path.</p><h2 id=creating-an-occupancy-matrix>Creating an occupancy matrix</h2><p>The data outputted from OSM is a list of shapes and points and their locations. We want to run a path planning algorithm on this data. We cannot do this though with the data in this format. Path planning algorithms require a graph to traverse (see how this works <a href=https://www.redblobgames.com/pathfinding/a-star/introduction.html>here</a>). The best way to convert multi-dimensional space into a graph is by breaking it up into square chunks where each chunk is a node in the graph. One structure these chunks can be broken into is a 2D or 3D matrix. Another structure is a <a href=https://en.wikipedia.org/wiki/Quadtree>quadtree</a> (2D) or <a href=http://www.open3d.org/docs/latest/tutorial/geometry/octree.html>octree</a> (3D). If a node in each type of matrix intersects an obstacle, we give it a value of 1 (occupied). Otherwise it has a value of 0. This is where the name &ldquo;occupancy matrix&rdquo; comes from. We can then take all of the nodes that are not occupied and link them together to create a graph that the path finding algorithm can traverse.</p><p>So, we need a solution that will convert our OSM data to an occupancy matrix.</p><h2 id=creating-a-3d-octree>Creating a 3D octree</h2><p>The first occupancy matrix we pursued creating was a 3D one.</p><p>We first researched if there were any libraries that could convert a 3D scene file like a .gltf to an occupancy matrix. We found a MATLAB function that could do this for us however we decided not to use this as it would lock us into using MATLAB&rsquo;s technology and if in the future we wanted to deploy this, we would have to pay MATLAB for computation. Therefore, we pushed on to try to find an open-source library that could do this. We ended up finding Open3D, a library that can convert a mesh like .gltf to a point cloud and then convert the point cloud to an octree. At the same time, we also found that the library OSM2World included a Command Line Interface that could convert a .osm file to a .gltf file. So, we used both tools together and ended up with a beautiful octree of campus!</p><h2 id=creating-a-2d-matrix>Creating a 2D matrix</h2><p>We were anticipating that the 3D occupancy matrix would be used in the initial flight planning and testing of the drone, however this was determined to be unecessary after we learned that we would would not be flying over buildings or trees for the first tests of the drone. Because we will not be flying over them, we could just use a 2D matrix that would document where every obstacle is located regardless of their height and thus the path planned would avoid flying over any of those obstacles.</p><p>Researching libraries that could do this for us, we found an R library that could take GeoJSON and output a matrix. However, we soon realized that the process of taking 2D shapes and converting them to a matrix is identical to the rasterization process your computer does when it is given the points of a shape like text and needs to calculate which pixels should be colored to show that text. So, we refined our search to look for libraries that could rasterize geospatail files. We finally found the Python library <a href=https://rasterio.readthedocs.io/en/latest/>Rasterio</a> that could rasterize GeoJSON into a TIFF file (an image file). All we needed to do is change the resolution of the image to fit our expected node dimensions.</p><p>The resulting converter created is located at this repository.</p><h2 id=future-plans>Future plans</h2><p>In the future we are going to use <a href=https://en.wikipedia.org/wiki/Photogrammetry>photogrammetry</a> for our obstacle data source. Photogrammetry is the technology used to generate 3D buildings in Google Maps. It is generated by taking images of features from multiple angles and the location and direction they were taken to create a 3D mesh.</p><p>Photogrammetry can be collected by flying our drone around its operating area and using images captured to generate photogrammetry.</p><p>The advantage of photogrametry over using OpenStreetMap data is it much more precise and easier to keep up-to-date than OpenStreetMap data. Photogrammetery can outline the precise geometries and locations of all obstacles in an area whereas OpenStreetMap can only document features to such detail and requires manually editing the map to document it. Photogrametry can also be much easier to keep up-to-date than OpenStreetMap. If a temporary construction area is setup where the drone typically flies, the drone can forward the imagery collected while it avoided the newly-found obstacle to the photogrametry world server to create fresh set of obstacle meshes that can will be accounted in the calculation of the flight path the next time a flight is planned through that area.</p><p>The reason photogrammetry was not chosen initially as the obstacle dataset was that we did not have a functional drone at the time of developing it to take the images used for photogrammetry.</p></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank rel=noopener href=https://mobile.twitter.com/purduerobotics aria-label=Twitter><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank rel=noopener href=https://github.com/purdue-arc aria-label=GitHub><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Discord aria-label=Discord><a class=text-white target=_blank rel=noopener href=https://discord.gg/ddkzfD2cyu aria-label=Discord><i class="fab fa-discord"></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2022 Purdue ARC All Rights Reserved</small>
<small class=ml-1><a href=https://policies.google.com/privacy target=_blank rel=noopener>Privacy Policy</a></small></div></div></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js integrity="sha512-UR25UO94eTnCVwjbXozyeVd6ZqpaAE9naiEUBK/A+QDbfSTQFhPGj5lOR6d8tsgbBk84Ggb5A3EkjsOgPRPcKA==" crossorigin=anonymous></script>
<script src=/js/tabpane-persist.js></script>
<script src=/js/main.min.aebb4087d608eeae579e098f961a0adca05a467aea516b216f2533775ccff5ce.js integrity="sha256-rrtAh9YI7q5XngmPlhoK3KBaRnrqUWshbyUzd1zP9c4=" crossorigin=anonymous></script></body></html>