<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Purdue ARC – Drone Delivery</title><link>https://purduearc.com/wiki/active-projects/drone-delivery/</link><description>Recent content in Drone Delivery on Purdue ARC</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://purduearc.com/wiki/active-projects/drone-delivery/index.xml" rel="self" type="application/rss+xml"/><item><title>Wiki: Fall 2022 Progress Updates</title><link>https://purduearc.com/wiki/active-projects/drone-delivery/fa22-updates/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://purduearc.com/wiki/active-projects/drone-delivery/fa22-updates/</guid><description>
&lt;img src="../images/nav_idea.png" alt="idea" width="400"/>
&lt;h3 id="pre-flight-planning">Pre-flight Planning&lt;/h3>
&lt;p>The idea was to generate a occupancy grid of campus that can be used as an occupancy grid.&lt;/p>
&lt;ul>
&lt;li>Used OpenStreetMap to generate a isolated 3d map of campus.
&lt;ul>
&lt;li>&lt;a href="https://www.openstreetmap.org/#map=5/38.007/-95.844">https://www.openstreetmap.org/#map=5/38.007/-95.844&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Converted that into a 2D map using Rasterization techniques.&lt;/li>
&lt;li>Initially planned on using Octrees, but later decided not to due to the vast amount of memory that would consume.&lt;/li>
&lt;li>Has a separate page, which describes the stack in much greater detail.&lt;/li>
&lt;/ul>
&lt;p>The following is the point cloud generated from OpenStreetMap.
&lt;img src="../images/point_cloud.png" alt="cloud" width="400"/>&lt;/p>
&lt;p>The Octree that was generated.
&lt;img src="../images/octree.png" alt="tree" width="400"/>&lt;/p>
&lt;p>The occupancy gird that was generated.
&lt;img src="../images/occupancy.png" alt="occupancy" width="400"/>&lt;/p>
&lt;h3 id="obstacle-avoidance">Obstacle Avoidance:&lt;/h3>
&lt;ul>
&lt;li>Migrate the code for Realsense camera from Python → C++
&lt;ul>
&lt;li>Able to get depth matrix&lt;/li>
&lt;li>Can convert to occupancy matrix&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Implimenting a the D* and A* algorithms.
&lt;ul>
&lt;li>There are issues in how the paths are generated, in that sometimes diagonal paths are taken over straight ones, even though the latter is possible to produce.&lt;/li>
&lt;li>To be improved in Spring 2023.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>OpenCV integration for detecting obstacles at a greater depth.&lt;/li>
&lt;/ul>
&lt;p>The Output from the A* algorithm we develped:
&lt;img src="../images/astar_path.png" alt="astar" width="400"/>&lt;/p>
&lt;p>An example of an unideal path:
&lt;img src="../images/sub_optimal.png" alt="erros" width="400"/>&lt;/p>
&lt;h3 id="hardware">Hardware:&lt;/h3>
&lt;ul>
&lt;li>Established mission objectives, such as flight time and pay load weight.&lt;/li>
&lt;li>Picked a drone kit, selected baterries, motor controllers, motors and propellers.
&lt;ul>
&lt;li>A detailed document describing all the design choices that were made:
&lt;a href="https://docs.google.com/document/d/1YcgpvD2AsxBpSHcqvRHN5PRzlyk0kKi2nl-Srrc2DXE/edit?usp=sharing">https://docs.google.com/document/d/1YcgpvD2AsxBpSHcqvRHN5PRzlyk0kKi2nl-Srrc2DXE/edit?usp=sharing&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Check the main page for details on what hardware components were selected.&lt;/li>
&lt;/ul>
&lt;h3 id="interfacing">Interfacing:&lt;/h3>
&lt;ul>
&lt;li>Repaired the old drone, and interfaced a computer with it.&lt;/li>
&lt;li>Simulated pre-programmed fight paths using Gazebo and QGroundControl.&lt;/li>
&lt;li>Worked on importing OpenStreetMap data into Gazebo.&lt;/li>
&lt;/ul>
&lt;img src="../images/sim.png" alt="sim" width="400"/>
&lt;h3 id="research">Research:&lt;/h3>
&lt;ul>
&lt;li>Over the course of the semester, the team reseached several important topics and developed whitepapers, and plan documents.
&lt;ul>
&lt;li>Deegan Osmundson: A* based navigation algorithms.
&lt;a href="https://drive.google.com/file/d/1XcB0w0IvobgjAYehDYUqe3qoPYX0miRA/view">https://drive.google.com/file/d/1XcB0w0IvobgjAYehDYUqe3qoPYX0miRA/view&lt;/a>&lt;/li>
&lt;li>Seth Deegan: Drone Delivery Tech Stack
&lt;a href="https://docs.google.com/document/d/1ekadDu0ogtgF6m-fK_AaudN6HzlPpPMSJ_rsvxW74-M/edit#heading=h.fliy5digh3xk">https://docs.google.com/document/d/1ekadDu0ogtgF6m-fK_AaudN6HzlPpPMSJ_rsvxW74-M/edit#heading=h.fliy5digh3xk&lt;/a>&lt;/li>
&lt;li>Sooraj Chetput: Steps in implimenting the software stack for DD.
&lt;a href="https://drive.google.com/file/d/1RyhzLklxlVaUF0ReHZfJ17z1Qm90ic8P/view">https://drive.google.com/file/d/1RyhzLklxlVaUF0ReHZfJ17z1Qm90ic8P/view&lt;/a>&lt;/li>
&lt;li>Jake Harrelson and several Authors: Design and Implementation of Unmanned Aerial Vehicle for Local Food Delivery
&lt;a href="https://docs.google.com/document/d/1YcgpvD2AsxBpSHcqvRHN5PRzlyk0kKi2nl-Srrc2DXE/view">https://docs.google.com/document/d/1YcgpvD2AsxBpSHcqvRHN5PRzlyk0kKi2nl-Srrc2DXE/view&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="acknowledgements">Acknowledgements:&lt;/h3>
&lt;ul>
&lt;li>Project Managers: Sooraj Chetput&lt;/li>
&lt;li>Obstacle Avoidance Team Members: Guna Avula (Lead), Deegan Osmundson, Chris Qiu, Ethan Baird, Mouli Sangita&lt;/li>
&lt;li>Pre-flight planning: Seth Deegan (Lead), Vincent Wang&lt;/li>
&lt;li>Research: Sreevickrant Sreekanth (Lead), Vignesh Charapalli&lt;/li>
&lt;li>Hardware: Jacob Harrelson (Lead), Evan Zher&lt;/li>
&lt;li>Interfacing: Sooraj Chetput (Lead), Atharva Bhide&lt;/li>
&lt;/ul></description></item><item><title>Wiki: Pre-flight path planning</title><link>https://purduearc.com/wiki/active-projects/drone-delivery/pre-flight-path-planning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://purduearc.com/wiki/active-projects/drone-delivery/pre-flight-path-planning/</guid><description>
&lt;h2 id="why">Why&lt;/h2>
&lt;p>The drone should fly a path known not to have obstacles so that we can minimize the amount of time avoiding obstacles during its flight.&lt;/p>
&lt;h2 id="getting-the-obstacle-data">Getting the obstacle data&lt;/h2>
&lt;p>We can get data of obstacles we want to avoid like buildings, trees, and lightposts from a geospatial data source.&lt;/p>
&lt;p>The geospatial data source we decided to use for our initial implementation was &lt;a href="https://www.openstreetmap.org">OpenStreetMap&lt;/a>. OpenStreetMap is a free-to-use map of the world that can be contributed to by anyone. A large variety of features can be mapped in OpenStreetMap including all of the obstacles we need to avoid: buildings, trees, and lightposts. Because OpenStreetMap data is free, can be updated by ourselves if data is missing, and has all the obstacles we need to avoid, it is a clear choice over Google Maps which is costly, cannot be updated, and does not have data on eveything we need to avoid.&lt;/p>
&lt;p>OpenStreetMap data is is made up of features. There are 3 types of features: points, lines, and areas. Lines and areas are ordered lists of points. Each point has a laditude and longitude and thus determines the position of a feature or the shape of a line or area in the world. To describe the type of feature such as &amp;ldquo;building&amp;rdquo; and attributes that feature has such as &amp;ldquo;levels&amp;rdquo; or &amp;ldquo;color&amp;rdquo;, every feature has a list of key-value pairs (a map/dictionary).&lt;/p>
&lt;p>We only want to get all of the buildings, trees, and streetlight features and not any of the other features in an area in OpenStreetMap, so we need to filter the features in a selected area by their tags.&lt;/p>
&lt;p>We can use the Overpass API querying service to get only these features. The Overpass API can be easily interfaced through by using &lt;a href="https://overpass-turbo.eu/">Overpass Turbo&lt;/a>. We can easily create a query clicking the &lt;code>Wizard&lt;/code> button at the top and inputting the tags we want.&lt;/p>
&lt;p>Every building in OSM has a tag with the key &lt;code>building&lt;/code>. The value of the &lt;code>building&lt;/code> tag determines the type of the building. For example, &lt;code>building=school&lt;/code>. We don&amp;rsquo;t care about the type of the building so we can just add &lt;code>building=*&lt;/code> to get all of the buildings that have a tag with the key &lt;code>buildling&lt;/code> regardless of its value.&lt;/p>
&lt;p>OSM allows users to document map individual parts of buildings to distinguish which parts have different attributes. For example, one part of a building might have more levels than another. The key for getting these &amp;ldquo;building part&amp;rdquo; features is &lt;code>building:part&lt;/code>. So, we can add &lt;code>or building:part=*&lt;/code> to also select all of these building parts.&lt;/p>
&lt;p>Finally, we want to get all of the trees. The tag for a tree is &lt;code>natural=tree&lt;/code> so we can add &lt;code>or natural=tree&lt;/code> to also select all of the trees.&lt;/p>
&lt;p>So, our final input inside of the query wizard should be &lt;code>building=* or building:part=* or natural=tree&lt;/code>. You can then click &lt;code>Build query&lt;/code> and the actual Overpass Query Language query text will appear on the left.&lt;/p>
&lt;p>To select the area of data you want to get, click the picture icon in the upper left of the map and click adjust the box on the map to &amp;ldquo;manually select the bbox&amp;rdquo;.&lt;/p>
&lt;p>Now, we click &lt;code>Run&lt;/code> in the upper right to run the query and return the data we need.&lt;/p>
&lt;blockquote>
&lt;p>Note, you might have selected a large area and it will give you a warning you are returning a lot of data. Click &lt;code>continue anyway&lt;/code>. You can minimize the impact this will have on your computer by disabling the results from showing on the map. This is done by removing the &lt;code>&amp;gt;; out skel qt;&lt;/code> at the end of the query and re-running it.&lt;/p>
&lt;/blockquote>
&lt;p>You can browse the data returned visually on the map or by clicking the &lt;code>Data&lt;/code> button in the upper right.&lt;/p>
&lt;p>The next step is to export the data. This can be done by clicking the &lt;code>Export&lt;/code> button at the top and selecting which file format to export to. What file format should be exported is dependent on the type of occupancy matrix needed. Read the following section to understand what an occupancy matrix is and how it will help us find a path.&lt;/p>
&lt;h2 id="creating-an-occupancy-matrix">Creating an occupancy matrix&lt;/h2>
&lt;p>The data outputted from OSM is a list of shapes and points and their locations. We want to run a path planning algorithm on this data. We cannot do this though with the data in this format. Path planning algorithms require a graph to traverse (see how this works &lt;a href="https://www.redblobgames.com/pathfinding/a-star/introduction.html">here&lt;/a>). The best way to convert multi-dimensional space into a graph is by breaking it up into square chunks where each chunk is a node in the graph. One structure these chunks can be broken into is a 2D or 3D matrix. Another structure is a &lt;a href="https://en.wikipedia.org/wiki/Quadtree">quadtree&lt;/a> (2D) or &lt;a href="http://www.open3d.org/docs/latest/tutorial/geometry/octree.html">octree&lt;/a> (3D). If a node in each type of matrix intersects an obstacle, we give it a value of 1 (occupied). Otherwise it has a value of 0. This is where the name &amp;ldquo;occupancy matrix&amp;rdquo; comes from. We can then take all of the nodes that are not occupied and link them together to create a graph that the path finding algorithm can traverse.&lt;/p>
&lt;p>So, we need a solution that will convert our OSM data to an occupancy matrix.&lt;/p>
&lt;h2 id="creating-a-3d-octree">Creating a 3D octree&lt;/h2>
&lt;p>The first occupancy matrix we pursued creating was a 3D one.&lt;/p>
&lt;p>We first researched if there were any libraries that could convert a 3D scene file like a .gltf to an occupancy matrix. We found a MATLAB function that could do this for us however we decided not to use this as it would lock us into using MATLAB&amp;rsquo;s technology and if in the future we wanted to deploy this, we would have to pay MATLAB for computation. Therefore, we pushed on to try to find an open-source library that could do this. We ended up finding Open3D, a library that can convert a mesh like .gltf to a point cloud and then convert the point cloud to an octree. At the same time, we also found that the library OSM2World included a Command Line Interface that could convert a .osm file to a .gltf file. So, we used both tools together and ended up with a beautiful octree of campus!&lt;/p>
&lt;h2 id="creating-a-2d-matrix">Creating a 2D matrix&lt;/h2>
&lt;p>We were anticipating that the 3D occupancy matrix would be used in the initial flight planning and testing of the drone, however this was determined to be unecessary after we learned that we would would not be flying over buildings or trees for the first tests of the drone. Because we will not be flying over them, we could just use a 2D matrix that would document where every obstacle is located regardless of their height and thus the path planned would avoid flying over any of those obstacles.&lt;/p>
&lt;p>Researching libraries that could do this for us, we found an R library that could take GeoJSON and output a matrix. However, we soon realized that the process of taking 2D shapes and converting them to a matrix is identical to the rasterization process your computer does when it is given the points of a shape like text and needs to calculate which pixels should be colored to show that text. So, we refined our search to look for libraries that could rasterize geospatail files. We finally found the Python library &lt;a href="https://rasterio.readthedocs.io/en/latest/">Rasterio&lt;/a> that could rasterize GeoJSON into a TIFF file (an image file). All we needed to do is change the resolution of the image to fit our expected node dimensions.&lt;/p>
&lt;p>The resulting converter created is located at this repository.&lt;/p>
&lt;h2 id="future-plans">Future plans&lt;/h2>
&lt;p>In the future we are going to use &lt;a href="https://en.wikipedia.org/wiki/Photogrammetry">photogrammetry&lt;/a> for our obstacle data source. Photogrammetry is the technology used to generate 3D buildings in Google Maps. It is generated by taking images of features from multiple angles and the location and direction they were taken to create a 3D mesh.&lt;/p>
&lt;p>Photogrammetry can be collected by flying our drone around its operating area and using images captured to generate photogrammetry.&lt;/p>
&lt;p>The advantage of photogrametry over using OpenStreetMap data is it much more precise and easier to keep up-to-date than OpenStreetMap data. Photogrammetery can outline the precise geometries and locations of all obstacles in an area whereas OpenStreetMap can only document features to such detail and requires manually editing the map to document it. Photogrametry can also be much easier to keep up-to-date than OpenStreetMap. If a temporary construction area is setup where the drone typically flies, the drone can forward the imagery collected while it avoided the newly-found obstacle to the photogrametry world server to create fresh set of obstacle meshes that can will be accounted in the calculation of the flight path the next time a flight is planned through that area.&lt;/p>
&lt;p>The reason photogrammetry was not chosen initially as the obstacle dataset was that we did not have a functional drone at the time of developing it to take the images used for photogrammetry.&lt;/p></description></item><item><title>Wiki:</title><link>https://purduearc.com/wiki/active-projects/drone-delivery/images/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://purduearc.com/wiki/active-projects/drone-delivery/images/</guid><description/></item></channel></rss>